<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="BeCircle&#39;s blog">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" type="image/ico" href="/css/images/logo.png"/>
  
  <title>
    
      Knowledge Graph Embedding Based Question Answering | 知芯
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/css/plugins/gitalk.css">

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
    
<script src="/js/qrious.js"></script>

  
  
    
<script src="/js/gitalk.js"></script>

  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  
<meta name="generator" content="Hexo 5.2.0"></head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>知芯</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/links/" class="item-link">Links</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/links/" class="menu-link">Links</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>Knowledge Graph Embedding Based Question Answering</h2>
  <p class="post-date">2020-09-25</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><p>百度团队发表在WSDM19年的<a target="_blank" rel="noopener" href="https://dl.acm.org/doi/abs/10.1145/3289600.3290956">文章</a>，<a target="_blank" rel="noopener" href="https://github.com/xhuang31/KEQA_WSDM19">源码</a>，<a target="_blank" rel="noopener" href="https://github.com/wbq813/KEQA_WSDM19">备用地址</a>。通过谓词划分数据集，使得训练集合测试集之间没有关联，用以验证模型泛化能力。分别验证每部分损失函数的作用。实体数量较多，直接用预测的实体去匹配复杂度高，通过识别实体名称，缩小候选实体范围。<br><code>KG embedding</code>将知识图谱表示成低维向量，使得在学习的向量中知识图谱原有的结构和关系得到保留。</p>
<h2 id="1-思想"><a href="#1-思想" class="headerlink" title="1. 思想"></a>1. 思想</h2><p><img src="keqa.png" alt="keqa"></p>
<ul>
<li>输入<br>  知识图谱$G$，带有答案、谓词标注、(谓词对应embedding向量)、实体标注、头实体标注、(头实体对应embedding向量) 的问题集$Q$</li>
<li>输出<br>  联合损失最小的候选答案。</li>
</ul>
<h3 id="1-1-Knowledge-Graph-Embedding"><a href="#1-1-Knowledge-Graph-Embedding" class="headerlink" title="1.1 Knowledge Graph Embedding"></a>1.1 Knowledge Graph Embedding</h3><p>$P$ 表示<code>predicates</code>的  <code>embedding</code>，$E$ 表示 <code>entities</code>的 <code>embedding</code>，$P$和$E$作为后续子任务的基础设施。文章使用现有<code>KG embedding</code>算法学习$P$和$E$。<br>对于知识图谱$G$中的每个事实$(h,l,t)$，对应的<code>embedding</code>表示为$(e_h, P_l, e_t)$，<code>embedding</code>算法将$e_h, P_l, e_t$随机初始化或者基于训练好的词向量(可用预训练模型?)初始化，函数$f(.)$定义事实在<code>embedding</code>中的关系$e_t \approx f(e_h, P_l)$，比如:<br>$$TransE: e_t \approx e_h + P_l$$ $$TransR: e_t M_l \approx e_h M_l + P_l $$ $M_l$是<code>predicates</code><br>$l$的变换矩阵。最后，算法最小化知识图谱$G$中所有事实的$e_t$和$f(e_h,P_l)$的距离。</p>
<h3 id="1-2-Predicate-and-Head-Entity-Learning-Model"><a href="#1-2-Predicate-and-Head-Entity-Learning-Model" class="headerlink" title="1.2 Predicate and Head Entity Learning Model"></a>1.2 Predicate and Head Entity Learning Model</h3><img src="predicate_head_learn_model.png" alt="predicate_head_learn_model" style="zoom: 33%;" />

<p>输入一个简单问句，找到在<code>predicates embedding</code>空间中的点，作为 <code>predicates</code>的表示$\hat{P}_l$，在<code>entities embedding</code>空间中的点，作为 <code>entities</code>的表示$\hat{e}_h$。能够被$G$回答的所有问题的<code>predicates</code>向量表示都应该在<code>predicates embedding</code>中，因此模型输入简单问题，返回<code>predicates embedding</code>中离$P_l$(标注)最近的向量$\hat{P}_l$(预测).</p>
<ul>
<li><p><code>Word Embedding</code><br>  问题长度<code>L</code>，基于预训练模型<code>Glove</code>将问题的<code>L</code>个<code>token</code>映射为词嵌入向量序列$\{x_j\}, j=1,…L$。</p>
</li>
<li><p><code>BiLSTM</code> 捕获词的不同重要性和顺序信息<br>  学习前向隐藏状态序列$(\overrightarrow{h}_1, \overrightarrow{h}_2, …, \overrightarrow{h}_L)$和后向隐藏状态序列$(\overleftarrow{h}_1, \overleftarrow{h}_2, …, \overleftarrow{h}_L)$，比如 $\{\overleftarrow{h}_j\}$通过如下公式计算：</p>
<p>  $$ForgetGate: f_j=\sigma(W_{xf}x_j+W_{hf}\overleftarrow{h}_{j+1}+b_f)$$</p>
<p>  $$InputGate: i_j=\sigma(W_{xj}x_j+W_{hi}\overleftarrow{h}_{j+1}+b_i)$$</p>
<p>  $$OutputGate: o_j=\sigma(W_{xo}x_j+W_{ho}\overleftarrow{h}_{j+1}+b_o)$$</p>
<p>  $$CellState: c_j=f_j \circ c_{j+1}+i_j\tanh(W_{xc}x_j+W_{hc}\overleftarrow{h}_{j+1}+b_c)$$</p>
<p>  $$\overleftarrow{h}_j=o_j \circ \tanh(c_j)$$</p>
<p>  连接前向后向隐藏状态向量$h_j=[\overrightarrow{h}_j; \overleftarrow{h}_j]$</p>
</li>
<li><p><code>Attention</code><br>  通过$h_j$和$x_j$计算<code>attention</code> 权重$\alpha_j$：</p>
<p>  $$q_j = \tanh(w^\top[x_j; h_j])+b_q$$ $$\alpha_j=\frac{exp(q_j)}{\sum_{i=j}^L exp(q_i)}$$</p>
</li>
<li><p>中间层<br>  将<code>attention</code> 权重应用到$h_j$，并与$x_j$连接得到新的隐藏状态$s_j=[x_j;\alpha_j h_j]$</p>
</li>
<li><p>全连接层<br>  在$s_j$上增加全连接层得到$r_j \epsilon R^{d \times 1}$就是第<code>j</code>个<code>token</code>的目标向量。</p>
</li>
<li><p>预测<code>predicate</code> $\hat{P}_{l}$</p>
<p>  $$= \frac{1}{L} \sum_{j=1}^L r_j^\top$$</p>
</li>
<li><p>损失函数: $||P_l-\frac{1}{L}\sum_{j=1}^\top||_2$ 和 $||e_h-\frac{1}{L}\sum_{j=1}^\top||_2$</p>
</li>
</ul>
<p>$\hat{e}_h$同样通过上述模型进行预测，得到的$\hat{e}_h$主要用于处理歧义问题。因为直接使用它与$E$中所有<code>entity</code>比较太耗时。使用下面的探测模型降低候选<code>head entity</code>的数量。</p>
<h3 id="1-3-Head-Entity-Detection-Model"><a href="#1-3-Head-Entity-Detection-Model" class="headerlink" title="1.3 Head Entity Detection Model"></a>1.3 Head Entity Detection Model</h3><img src="hed.png" alt="hed" style="zoom: 50%;" />
训练数据为问题$Q$和对应的实体名称标注。
下层的`BiLSTEM`与前面一致，通过全连接层后接入`SoftMax`得到的结果$v_j \epsilon R^{2 \times 1}$ ，$v_j$的两个值分别表示`token j`是实体名称的概率和不是实体名称的概率。

<p>需要注意，候选实体可能只是真正实体的一部分，因此包含这些实体名称的都作为候选<code>head entity</code>，<code>head entity</code>属于候选<code>head entity</code>的三元组是候选三元组$C$，这就缩小了直接用$\hat{e}_h$去比较的复杂度。</p>
<h3 id="1-4-Join-Search-On-Embedding-Spaces"><a href="#1-4-Join-Search-On-Embedding-Spaces" class="headerlink" title="1.4 Join Search On Embedding Spaces"></a>1.4 Join Search On Embedding Spaces</h3><p>前面的步骤能够得到一个问题的<code>predicate</code>和<code>head entity</code>的表示 $\hat{p}_l$和$\hat{e}_h$，以及候选的<code>head entity</code>。还需要从$G$中找出最符合$\hat{p}_l$和$\hat{e}_h$的三元组，也就是从候选三元组$C$中寻找。通过如下公式表示一个候选三元组$(h,l,t)$与$(\hat{p}_l, \hat{e}_h)$的距离：<br>$$||p_l-\hat{p}_l||_2+\beta_1||e_h-\hat{e}_h||_2+\beta_2||f(e_h, P_l)-\hat{e}_t||_2$$</p>
<p>$$-\beta_3sim[n(h),HED_{entity}]-\beta_4sim[n(l),HED_{non}]$$<br>前半段表示三元组和预测结果在<code>embedding</code>空间的距离，这里使用$f(e_h, P_l)$表示$e_t$，因为$G$中可能存在$e_h, P_l$相同，但是$e_t$不同的情况。另外$\hat{e}_t$也是通过$f(.)$计算得到的。</p>
<p>第二段表示，我们倾向于选择<code>head</code>与$HED_{entity}$一致，<code>predicate</code>被问题提及的三元组。</p>
<h2 id="2-实验"><a href="#2-实验" class="headerlink" title="2. 实验"></a>2. 实验</h2><h3 id="2-1-数据"><a href="#2-1-数据" class="headerlink" title="2.1 数据"></a>2.1 数据</h3><p><code>FB2M</code>和<code>FB5M</code>是<code>FreeBase</code>的两个子集。</p>
<h3 id="2-2-3组实验"><a href="#2-2-3组实验" class="headerlink" title="2.2 3组实验"></a>2.2 3组实验</h3><ol>
<li>在<code>FB2M</code>的<code>accuracy</code>和<code>FB5M</code>(指标未说明)<br>证明了准确率有所提高，并且证明本文所述方法在有<code>embedding</code>时效果更好。</li>
<li>三种不同<code>embedding</code>算法以及没有<code>embedding</code>对比<br>证明了<code>embedding</code>的提升，另外按照谓词划分数据集，这种数据划分下训练集和测试集没有直接关系，证明了有<code>embedding</code>的方法具有泛化能力。这种数据划分方式值得学习。</li>
<li>联合搜索损失函数的每个部分<br>通过只保留、移除、累加三种方式处理损失函数的每个部分，证明每个部分的作用。谓词之间的距离贡献最大(第一个部分)；谓词和头实体加在一起提升较大，而且可以做联合学习；最后一个部分提升1.1，可能因为有些问题和对应谓词有相同的词语。</li>
</ol>
<h2 id="0-个人感悟"><a href="#0-个人感悟" class="headerlink" title="0. 个人感悟"></a>0. 个人感悟</h2><p>实习回来，浮躁了一段时间，是时候静下心来准备毕业论文了，非常惭愧，读研两年了，静下心看论文的情况并不多。在《极客时间》的《卖桃者说》听到一个观点，有输出的学习才会更加有效，认真输出的内容会得到反馈，反馈能够促使自己更加热爱学习。所谓的正向循环就是如此，不过就是利用邪恶的多巴胺。自己在这方面确实有所欠缺，半年前听到实验室大佬谈论<strong>正向循环</strong>，自己也尝试调整自己，寻找自己的正向循环，但疲于奔命，不了了之。重新整理了一下博客，支持公式输入，望借此构成自己阅读论文的正向循环，重新起航。</p>
</section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#kbqa" >
    <span class="tag-code">kbqa</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2020/09/01/java-serilize/">
        <span class="nav-arrow">← </span>
        
          Java 序列化
        
      </a>
    
    
      <a class="nav-right" href="/2020/09/26/%E9%98%85%E8%AF%BB-%E6%B2%89%E9%BB%98%E4%B9%9F%E4%BC%9A%E6%AD%8C%E5%94%B1/">
        
          阅读-《沉默也会歌唱》
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
      <div class="money-like">
        <div class="reward-btn">
          赏
          <span class="money-code">
            <span class="alipay-code">
              <div class="code-image"></div>
              <b>使用支付宝打赏</b>
            </span>
            <span class="wechat-code">
              <div class="code-image"></div>
              <b>使用微信打赏</b>
            </span>
          </span>
        </div>
        <p class="notice">若你觉得我的文章对你有帮助，欢迎点击上方按钮对我打赏</p>
      </div>
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
      <div class="qrcode">
        <canvas id="share-qrcode"></canvas>
        <p class="notice">扫描二维码，分享此文章</p>
      </div>
    
    <!-- 二维码 END -->
    
      <!-- Gitment START -->
      <!-- <div id="comments"></div> -->
      <div id="gitalk-container"></div>
      <!-- Gitment END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-%E6%80%9D%E6%83%B3"><span class="toc-nav-text">1. 思想</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1-1-Knowledge-Graph-Embedding"><span class="toc-nav-text">1.1 Knowledge Graph Embedding</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1-2-Predicate-and-Head-Entity-Learning-Model"><span class="toc-nav-text">1.2 Predicate and Head Entity Learning Model</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1-3-Head-Entity-Detection-Model"><span class="toc-nav-text">1.3 Head Entity Detection Model</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1-4-Join-Search-On-Embedding-Spaces"><span class="toc-nav-text">1.4 Join Search On Embedding Spaces</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-%E5%AE%9E%E9%AA%8C"><span class="toc-nav-text">2. 实验</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-1-%E6%95%B0%E6%8D%AE"><span class="toc-nav-text">2.1 数据</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-2-3%E7%BB%84%E5%AE%9E%E9%AA%8C"><span class="toc-nav-text">2.2 3组实验</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#0-%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F"><span class="toc-nav-text">0. 个人感悟</span></a></li></ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://codeyourlife.cn/2020/09/25/Knowledge-Graph-Embedding-Based-Question-Answering/';
    var banner = ''
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

    // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()

        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })
  })();
</script>


  <script>
    var qr = new QRious({
      element: document.getElementById('share-qrcode'),
      value: document.location.href
    });
  </script>



  <script>
    var gitmentConfig = "BeCircle";
    if (gitmentConfig !== 'undefined') {
      // var gitment = new Gitment({
      //   id: "Knowledge Graph Embedding Based Question Answering",
      //   owner: "BeCircle",
      //   repo: "BeCircle.github.io",
      //   oauth: {
      //     client_id: "ceb721601c4da2d6b245",
      //     client_secret: "b8adcfeb9c822281b434e5e9116adb3a852473f7"
      //   },
      //   theme: {
      //     render(state, instance) {
      //       const container = document.createElement('div')
      //       container.lang = "en-US"
      //       container.className = 'gitment-container gitment-root-container'
      //       container.appendChild(instance.renderHeader(state, instance))
      //       container.appendChild(instance.renderEditor(state, instance))
      //       container.appendChild(instance.renderComments(state, instance))
      //       container.appendChild(instance.renderFooter(state, instance))
      //       return container;
      //     }
      //   }
      // })
      // gitment.render(document.getElementById('comments'))

      const gitalk = new Gitalk({
        clientID: "ceb721601c4da2d6b245",
        clientSecret: "b8adcfeb9c822281b434e5e9116adb3a852473f7",
        repo: "BeCircle.github.io",      // The repository of store comments,
        owner: "BeCircle",
        admin: ['BeCircle'],
        id: "Knowledge Graph Embedding Based Question Answering",      // Ensure uniqueness and length less than 50
        distractionFreeMode: false  // Facebook-like distraction free mode
      })

      gitalk.render('gitalk-container')
    }
  </script>




    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2014-2020 知芯 | <a href="http://www.beian.miit.gov.cn/" target="_blank">蜀ICP备19028913号</a>
    <br>
    Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a> | Theme by <a target="_blank" rel="noopener" href="https://github.com/yanm1ng">yanm1ng</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->

<script>
    var _baId = '662f6fea89ec7be261fab4b5a14776e2';
    // Originial
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>


<script src="/js/script.js"></script>

  </body>
</html>